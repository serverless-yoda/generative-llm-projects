{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyUT_4__Aguo"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index-vector-stores-deeplake\n",
        "!pip install deeplake\n",
        "!pip install llama-index\n",
        "!pip install sentence-transformers\n",
        "!pip install langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdvZIiySAgut"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import requests\n",
        "import re\n",
        "\n",
        "from google.colab import userdata\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Document\n",
        "from llama_index.vector_stores.deeplake import DeepLakeVectorStore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6j06MYKAgut"
      },
      "source": [
        "### 1.Retrieve and clean documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hFTTHk4Aguu"
      },
      "outputs": [],
      "source": [
        "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['USER_AGENT'] = 'RAGUserAgent'\n",
        "os.environ['ACTIVELOOP_TOKEN']= userdata.get('ACTIVELOOP_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydcLTGbcAguv"
      },
      "outputs": [],
      "source": [
        "urls = [\n",
        "    \"https://github.com/VisDrone/VisDrone-Dataset\",\n",
        "    \"https://paperswithcode.com/dataset/visdrone\",\n",
        "    \"https://openaccess.thecvf.com/content_ECCVW_2018/papers/11133/Zhu_VisDrone-DET2018_The_Vision_Meets_Drone_Object_Detection_in_Image_Challenge_ECCVW_2018_paper.pdf\",\n",
        "    \"https://github.com/VisDrone/VisDrone2018-MOT-toolkit\",\n",
        "    \"https://en.wikipedia.org/wiki/Object_detection\",\n",
        "    \"https://en.wikipedia.org/wiki/Computer_vision\",\n",
        "    \"https://en.wikipedia.org/wiki/Convolutional_neural_network\",\n",
        "    \"https://en.wikipedia.org/wiki/Unmanned_aerial_vehicle\",\n",
        "    \"https://www.faa.gov/uas/\",\n",
        "    \"https://www.tensorflow.org/\",\n",
        "    \"https://pytorch.org/\",\n",
        "    \"https://keras.io/\",\n",
        "    \"https://arxiv.org/abs/1804.06985\",\n",
        "    \"https://arxiv.org/abs/2202.11983\",\n",
        "    \"https://motchallenge.net/\",\n",
        "    \"http://www.cvlibs.net/datasets/kitti/\",\n",
        "    \"https://www.dronedeploy.com/\",\n",
        "    \"https://www.dji.com/\",\n",
        "    \"https://arxiv.org/\",\n",
        "    \"https://openaccess.thecvf.com/\",\n",
        "    \"https://roboflow.com/\",\n",
        "    \"https://www.kaggle.com/\",\n",
        "    \"https://paperswithcode.com/\",\n",
        "    \"https://github.com/\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQ9v_QztAguv"
      },
      "outputs": [],
      "source": [
        "def clean_text(content):\n",
        "    content = re.sub(r'\\[\\s*(\\d+|edit)\\s*\\]','',content)\n",
        "    content = re.sub(r'[^\\w\\s\\.]','',content)\n",
        "    return content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrjOvObVAguv"
      },
      "outputs": [],
      "source": [
        "def fetch(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        content = soup.find('div',{'class': 'mw-parser-output'}) or soup.find('div', {'id': 'content'})\n",
        "        if content is None:\n",
        "            return None\n",
        "\n",
        "        for section_title in ['References', 'Bibliography', 'External links', 'See also', 'Notes']:\n",
        "            section = content.find('span',id=section_title)\n",
        "            while section:\n",
        "                for sib in section.parent.find_next_siblings():\n",
        "                    sib.decompose()\n",
        "                section.parent.decompose()\n",
        "                section = content.find('span',id=section_title)\n",
        "\n",
        "        text = content.get_text(separator=' ', strip=True)\n",
        "        text = clean_text(text)\n",
        "        return text\n",
        "\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f'error from {url}: {e}')\n",
        "        return None\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_PATH = './contents/'"
      ],
      "metadata": {
        "id": "-xAq3hlCDjvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LX2jcT1xAguv"
      },
      "outputs": [],
      "source": [
        "\n",
        "for url in urls:\n",
        "    article = url.split('/')[-1].replace('.html','')\n",
        "\n",
        "    filename = os.path.join(LLM_PATH, f'{article}.txt')\n",
        "    clean_article = fetch(url)\n",
        "    if clean_article:\n",
        "        with open(filename,'w',encoding='utf-8') as file:\n",
        "            file.write(clean_article)\n",
        "            print(f'\\tContent was written to {filename}')\n",
        "\n",
        "print('Content writing done...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUPQe5iZAguv"
      },
      "outputs": [],
      "source": [
        "documents = SimpleDirectoryReader(LLM_PATH).load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7wLjBHZAguw"
      },
      "outputs": [],
      "source": [
        "documents[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsrvp0FIAgux"
      },
      "source": [
        "### 2.Create and load data to DeepLake Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLvA8xMSAgux"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import StorageContext\n",
        "from pydantic.v1 import BaseModel,Field\n",
        "from typing import ClassVar\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "import deeplake\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rox3x1IVAgux"
      },
      "outputs": [],
      "source": [
        "vector_path = 'hub://pythoninaction/drone_1000'\n",
        "dataset_path = 'hub://pythoninaction/drone_1000'\n",
        "\n",
        "gemini_embedding = GoogleGenerativeAIEmbeddings(model='models/embedding-001')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1gIou67Agux"
      },
      "outputs": [],
      "source": [
        "vector_store = DeepLakeVectorStore(dataset_path=dataset_path, overwrite=True)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVVT7vzkAguy"
      },
      "outputs": [],
      "source": [
        "# create index\n",
        "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)#, embedding=gemini_embedding, config=Config())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = deeplake.load(dataset_path)"
      ],
      "metadata": {
        "id": "anJMyWelEwYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'ds' is your loaded Deep Lake dataset\n",
        "\n",
        "# Create a dictionary to hold the data\n",
        "data = {}\n",
        "\n",
        "# Iterate through the tensors in the dataset\n",
        "for tensor_name in ds.tensors:\n",
        "    tensor_data = ds[tensor_name].numpy()\n",
        "\n",
        "    # Check if the tensor is multi-dimensional\n",
        "    if tensor_data.ndim > 1:\n",
        "        # Flatten multi-dimensional tensors\n",
        "        data[tensor_name] = [np.array(e).flatten().tolist() for e in tensor_data]\n",
        "    else:\n",
        "        # Convert 1D tensors directly to lists and decode text\n",
        "        if tensor_name == \"text\":\n",
        "            data[tensor_name] = [t.tobytes().decode('utf-8') if t else \"\" for t in tensor_data]\n",
        "        else:\n",
        "            data[tensor_name] = tensor_data.tolist()\n",
        "\n",
        "# Create a Pandas DataFrame from the dictionary\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "-DGbcMVtFpXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display a selected record\n",
        "def display_record(record_number):\n",
        "    record = df.iloc[record_number]\n",
        "    display_data = {\n",
        "        \"ID\": record.get(\"id\", \"N/A\"),\n",
        "        \"Metadata\": record.get(\"metadata\", \"N/A\"),\n",
        "        \"Text\": record.get(\"text\", \"N/A\"),\n",
        "        \"Embedding\": record.get(\"embedding\", \"N/A\")\n",
        "    }\n",
        "\n",
        "    # Print the ID\n",
        "    print(\"ID:\")\n",
        "    print(display_data[\"ID\"])\n",
        "    print()\n",
        "\n",
        "    # Print the metadata in a structured format\n",
        "    print(\"Metadata:\")\n",
        "    metadata = display_data[\"Metadata\"]\n",
        "    if isinstance(metadata, list):\n",
        "        for item in metadata:\n",
        "            for key, value in item.items():\n",
        "                print(f\"{key}: {value}\")\n",
        "            print()\n",
        "    else:\n",
        "        print(metadata)\n",
        "    print()\n",
        "\n",
        "    # Print the text\n",
        "    print(\"Text:\")\n",
        "    print(display_data[\"Text\"])\n",
        "    print()\n",
        "\n",
        "    # Print the embedding\n",
        "    print(\"Embedding:\")\n",
        "    print(display_data[\"Embedding\"])\n",
        "    print()\n",
        "\n",
        "# Function call to display a record\n",
        "rec = 0  # Replace with the desired record number\n",
        "display_record(rec)"
      ],
      "metadata": {
        "id": "YERzUdgUFpF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure 'text' column is of type string\n",
        "df['text'] = df['text'].astype(str)\n",
        "# Create documents with IDs\n",
        "documents = [Document(text=row['text'], doc_id=str(row['id'])) for _, row in df.iterrows()]"
      ],
      "metadata": {
        "id": "oeHPb1aAGoKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.RAG Index Based"
      ],
      "metadata": {
        "id": "ZAUiqfhGGx85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Can drones identify moving objects like boad or vehicle?\"\n",
        "\n",
        "# CONSTANT\n",
        "K=3\n",
        "TEMPERATURE=0.1\n",
        "MT=1024"
      ],
      "metadata": {
        "id": "7edNJp3FG3ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kXDDcTsGaPn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('all-MiniLM-l6-v2')"
      ],
      "metadata": {
        "id": "bnx6-3BGaZGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_cosine_similarity(str1,str2):\n",
        "  embeddings = model.encode([str1,str2])\n",
        "  similarity = cosine_similarity(embeddings)\n",
        "  return similarity[0][0]"
      ],
      "metadata": {
        "id": "8XS1TIxHaqKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Index Query Engine"
      ],
      "metadata": {
        "id": "TfRmYSk_bDKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "vector_store_index = VectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "id": "wcPnhVrLbQ5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(vector_store_index))"
      ],
      "metadata": {
        "id": "2nILPjsybehJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_engine = vector_store_index.as_query_engine(similarity_top_k=K,num_output=MT,temperature=TEMPERATURE)"
      ],
      "metadata": {
        "id": "jW1Z5Zc_bkRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(vector_engine))"
      ],
      "metadata": {
        "id": "RayazuzVb0Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Response of Index Query Engine"
      ],
      "metadata": {
        "id": "t2j4ZuEDcyke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import textwrap\n",
        "\n",
        "def test_index_query_engine(query):\n",
        "    response = vector_engine.query(query)\n",
        "\n",
        "    print(textwrap.fill(str(response), 100))\n",
        "\n",
        "    node_data = []\n",
        "    for node_with_score in response.source_nodes:\n",
        "        node = node_with_score.node\n",
        "        node_info = {\n",
        "            'NodeID': node.id_,\n",
        "            'Score': node_with_score.score,\n",
        "            'Text': node.text\n",
        "        }\n",
        "        node_data.append(node_info)\n",
        "\n",
        "    df = pd.DataFrame(node_data)\n",
        "\n",
        "    return df, response"
      ],
      "metadata": {
        "id": "FTbxjzgnc3ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "#timer start\n",
        "start_time = time.time()\n",
        "df, response = test_index_query_engine(question)\n",
        "\n",
        "# time end\n",
        "end_time = time.time()\n",
        "\n",
        "# check speed of response\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Query execution time: {elapsed_time:.4f} seconds\")\n",
        "\n",
        " # Display the DataFrame using markdown\n",
        "print(df.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "nodeid = response.source_nodes[0].node.id_\n",
        "print(nodeid)\n",
        "text = response.source_nodes[0].get_text()\n",
        "print(text)"
      ],
      "metadata": {
        "id": "QxdCc1pIdJw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metric Performance"
      ],
      "metadata": {
        "id": "1yz9C_YzRvHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def metric_performance(response):\n",
        "  # Calculate the performance (handling None scores)\n",
        "  scores = [node.score for node in response.source_nodes if node.score is not None]\n",
        "  if scores:  # Check if there are any valid scores\n",
        "      weights = np.exp(scores) / np.sum(np.exp(scores))\n",
        "      perf = np.average(scores, weights=weights) / elapsed_time\n",
        "  else:\n",
        "      perf = 0  # Or some other default value if all scores are None\n",
        "\n",
        "  average_score=np.average(scores, weights=weights)\n",
        "  print(f\"Average score: {average_score:.4f}\")\n",
        "  print(f\"Query execution time: {elapsed_time:.4f} seconds\")\n",
        "  print(f\"Performance metric: {perf:.4f}\")\n",
        "\n",
        "\n",
        "metric_performance(response)"
      ],
      "metadata": {
        "id": "flL6juA_RyFG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "generative-llm-projects",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}