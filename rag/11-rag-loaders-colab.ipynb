{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "0NMk584BdCY-"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade pip\n",
        "\n",
        "# Uninstall conflicting packages\n",
        "%pip uninstall -y langchain-core langchain-openai langchain-experimental langchain-community langchain chromadb beautifulsoup4 python-dotenv PyPDF2 rank_bm25 bs4 python-docx docx2txt jq\n",
        "\n",
        "# Install compatible versions of langchain libraries\n",
        "%pip install langchain-core==0.3.6\n",
        "%pip install langchain-openai==0.2.1\n",
        "%pip install langchain-experimental==0.3.2\n",
        "%pip install langchain-community==0.3.1\n",
        "%pip install langchain==0.3.1\n",
        "\n",
        "# Install remaining packages\n",
        "%pip install chromadb==0.5.11\n",
        "%pip install beautifulsoup4==4.12.3\n",
        "%pip install python-dotenv==1.0.1\n",
        "%pip install PyPDF2==3.0.1 -q --user\n",
        "%pip install rank_bm25==0.2.2\n",
        "\n",
        "# New installs for document loaders\n",
        "%pip install bs4==0.0.2\n",
        "%pip install python-docx==1.1.2\n",
        "%pip install docx2txt==0.8\n",
        "%pip install jq==1.8.0\n",
        "\n",
        "%pip install langchain-google-genai\n",
        "%pip install --upgrade langchain-together==0.2.0\n",
        "%pip install --upgrade --quiet pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from enum import Enum\n",
        "\n",
        "os.environ['USER_AGENT'] = 'RAGUserAgent'\n",
        "\n",
        "import openai\n",
        "import chromadb\n",
        "import langchain\n",
        "from langchain import hub\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_together import ChatTogether\n",
        "\n",
        "# core\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.documents.base import Document\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
        "\n",
        "# community\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.document_loaders import MergedDataLoader\n",
        "\n",
        "# retriever\n",
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "# splitter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# google\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "# other\n",
        "import pypdf\n",
        "from PyPDF2 import PdfReader\n",
        "from bs4 import BeautifulSoup\n",
        "import docx\n",
        "import json\n",
        "\n",
        "\n",
        "#  loader\n",
        "from langchain_community.document_loaders import Docx2txtLoader\n",
        "from langchain_community.document_loaders import JSONLoader\n",
        "from langchain_community.document_loaders import BSHTMLLoader\n",
        "from langchain_community.document_loaders import PyPDFLoader\n"
      ],
      "metadata": {
        "id": "wBuiWql0hG9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SourceType(Enum):\n",
        "  PDF = 'pdf'\n",
        "  HTML = 'html'\n",
        "  DOCX = 'docx'"
      ],
      "metadata": {
        "id": "m-BZaT1svOnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_loader():\n",
        "  based_path = '/content/sample_data/google-2023-environmental-report'\n",
        "  extensions= ['html','docx']\n",
        "\n",
        "  # pdf_loader = PyPDFLoader(file_path=f'{based_path}.pdf')\n",
        "  # html_loader = BSHTMLLoader(f'{based_path}.html')\n",
        "  # docx_loader = Docx2txtLoader(f'{based_path}.docx')\n",
        "  # json_loader = JSONLoader(file_path=f'{based_path}.json',jq_schema=\".txt\")\n",
        "\n",
        "  # combined_loader = MergedDataLoader(loaders=[json_loader])\n",
        "\n",
        "  # docs = combined_loader.load()\n",
        "  loader = JSONLoader(\n",
        "    file_path=f'{based_path}.json',\n",
        "    jq_schema='.text',\n",
        "  )\n",
        "\n",
        "  docs = []\n",
        "  with open(f'{based_path}.pdf', \"rb\") as pdf_file:\n",
        "    pdf_reader = PdfReader(pdf_file)\n",
        "    pdf_text = \"\".join(page.extract_text() for page in pdf_reader.pages)\n",
        "    docs = [Document(page_content=page) for page in pdf_text.split(\"\\n\\n\")]\n",
        "\n",
        "\n",
        "  return docs"
      ],
      "metadata": {
        "id": "XHHSVNbeE-2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "  return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "def extract_score(llm_output):\n",
        "  score = 0\n",
        "  try:\n",
        "    score = float(llm_output.strip())\n",
        "  except ValueError:\n",
        "    pass\n",
        "  return score\n",
        "\n",
        "def conditional_answer(x):\n",
        "  relevance_score = extract_score(x['relevance_score'])\n",
        "  if relevance_score < 4:\n",
        "    return \"I have no idea\"\n",
        "  else:\n",
        "    return x['answer']"
      ],
      "metadata": {
        "id": "0PeTlbOUrBZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_test_files(source):\n",
        "  based_path = '/content/sample_data/google-2023-environmental-report'\n",
        "  with open(source,'rb') as pdf_file:\n",
        "    pdf_reader = PdfReader(pdf_file)\n",
        "    pdf_text = \"\".join(page.extract_text() for page in pdf_reader.pages)\n",
        "\n",
        "    #create html\n",
        "    soup = BeautifulSoup(\"<htm><body></body></html>\", 'html.parser')\n",
        "    soup.body.append(pdf_text)\n",
        "    with open(f'{based_path}.html', 'w', encoding='utf-8') as html_file:\n",
        "      html_file.write(str(soup))\n",
        "\n",
        "    #create doc\n",
        "    doc = docx.Document()\n",
        "    doc.add_paragraph(pdf_text)\n",
        "    doc.save(f'{based_path}.docx')\n",
        "\n",
        "    #create json\n",
        "    with open(f'{based_path}.json', 'w', encoding='utf-8') as json_file:\n",
        "      json.dump({'text': pdf_text}, json_file, ensure_ascii=False, indent=4)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nwR-KDB11UpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RagPipeline:\n",
        "  def __init__(self,  source_path):\n",
        "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "    os.environ['TOGETHER_API_KEY'] = userdata.get('TOGETHER_API_KEY')\n",
        "    os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "    openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "\n",
        "    self.source_path = source_path\n",
        "    self.llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
        "    self.str_output_parser = StrOutputParser()\n",
        "    self.gemini_embeddings = GoogleGenerativeAIEmbeddings(model='models/embedding-001')\n",
        "    self.prompt = hub.pull('jclemens24/rag-prompt')\n",
        "\n",
        "    self.relevance_prompt_template = PromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "          Given the following question and retrieved context, determine if the context is relevant to the question.\n",
        "          Provide a score from 1 to 5, where 1 is not at all relevant and 5 is highly relevant.\n",
        "          Return ONLY the numeric score, without any additional text or explanation.\n",
        "\n",
        "          Question: {question}\n",
        "          Retrieved Context: {retrieved_context}\n",
        "\n",
        "          Relevance Score:\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    create_test_files(self.source_path)\n",
        "\n",
        "  def retriever(self):\n",
        "    #docs = data_loader()\n",
        "    docs = []\n",
        "    with open(self.source_path, \"rb\") as pdf_file:\n",
        "        pdf_reader = PdfReader(pdf_file)\n",
        "        pdf_text = \"\".join(page.extract_text() for page in pdf_reader.pages)\n",
        "        docs = [Document(page_content=page) for page in pdf_text.split(\"\\n\\n\")]\n",
        "\n",
        "    character_splitter = RecursiveCharacterTextSplitter(\n",
        "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200\n",
        "      )\n",
        "\n",
        "    splits = character_splitter.split_documents(docs)\n",
        "\n",
        "\n",
        "    dense_documents=[Document(page_content=doc.page_content, metadata={\n",
        "        \"id\": str(i),\"source\": \"dense\"\n",
        "    }) for i, doc in enumerate(splits)]\n",
        "\n",
        "    sparse_documents=[Document(page_content=doc.page_content, metadata={\n",
        "        \"id\": str(i), \"source\": \"sparse\"\n",
        "    }) for i, doc in enumerate(splits)]\n",
        "\n",
        "    vector_store = Chroma.from_documents(\n",
        "        documents=dense_documents,\n",
        "        embedding=self.gemini_embeddings,\n",
        "        collection_name=\"google_initiative\",\n",
        "        client=chromadb.Client()\n",
        "    )\n",
        "\n",
        "    dense_retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
        "    sparse_retriever = BM25Retriever.from_documents(sparse_documents)\n",
        "\n",
        "    ensemble_retriever = EnsembleRetriever(\n",
        "        retrievers=[dense_retriever, sparse_retriever],\n",
        "        weights=[0.7, 0.3]\n",
        "    )\n",
        "\n",
        "    return ensemble_retriever\n",
        "\n",
        "  def augmenter(self, retriever):\n",
        "    rag_chain_from_docs = (\n",
        "          RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
        "          | RunnableParallel(\n",
        "              {\"relevance_score\": (\n",
        "                  RunnablePassthrough()\n",
        "                  | (lambda x: self.relevance_prompt_template.format(question=x['question'], retrieved_context=x['context']))\n",
        "                  | self.llm\n",
        "                  | self.str_output_parser\n",
        "              ), \"answer\": (\n",
        "                  RunnablePassthrough()\n",
        "                  | self.prompt\n",
        "                  | self.llm\n",
        "                  | self.str_output_parser\n",
        "              )}\n",
        "          )\n",
        "          | RunnablePassthrough().assign(final_answer=conditional_answer)\n",
        "\n",
        "      )\n",
        "\n",
        "    rag_chain_with_source = RunnableParallel(\n",
        "          {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "      ).assign(answer=rag_chain_from_docs)\n",
        "\n",
        "    return rag_chain_with_source\n",
        "\n",
        "  def generator(self,question,chain):\n",
        "    result = chain.invoke(question)\n",
        "    print(result)\n",
        "    # retrieved_docs = result['context']\n",
        "    # print(f\"Original Question: {question}\\n\")\n",
        "    # print(f\"Relevance Score: {result['answer']['relevance_score']}\\n\")\n",
        "    # print(f\"Final Answer:\\n{result['answer']['final_answer']}\\n\\n\")\n",
        "    # print(\"Retrieved Documents:\")\n",
        "    # for i, doc in enumerate(retrieved_docs, start=1):\n",
        "    #   print(f\"Document {i}: Document ID: {doc.metadata[self.id]} source: {doc.metadata['source']}\")\n",
        "    #   print(f\"Content:\\n{doc.page_content}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "CSrWFLhqu-m7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag = RagPipeline('/content/sample_data/google-2023-environmental-report.pdf')"
      ],
      "metadata": {
        "id": "K10fDwyW45U2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chainer = rag.retriever()"
      ],
      "metadata": {
        "id": "6ZitCH4sIuoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag.generator(\"What are Google's environmental initiatives?\",chainer)"
      ],
      "metadata": {
        "id": "xAJFZdW4C-Pc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}