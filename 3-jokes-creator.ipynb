{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This app will create a funny joke using different models provided by ``OpenAI``, ``Anthropic`` and ``Google``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "\n",
    "# LLM'\n",
    "import openai\n",
    "import google.generativeai as genai\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TheJoker():\n",
    "\n",
    "    def __init__(self,about:str=None):\n",
    "        \n",
    "        self.user_prompt = f\"Give me an explosive jokes about {about}. Make it unique and super funny and readers will burst into laughter.\"\n",
    "        self.system_prompt = \"\"\"You are a good story teller specializing \n",
    "        on funny jokes to all type of audience.\n",
    "        You always tell a very unique and entertaining jokes.\n",
    "        \n",
    "        Include the LLM model you used after the joke\n",
    "\n",
    "        ex: created by gpt-3.5-turbo\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        self.frontier_list= [\n",
    "            'openai',\n",
    "            'google',\n",
    "            'anthropic'\n",
    "        ]\n",
    "\n",
    "        self.llm_models = {\n",
    "            'openai': {'transformers': ['gpt-3.5-turbo','gpt-4o-mini','gpt-4o'],'temperature': 0.8,'key': os.getenv('OPENAI_API_KEY'),'active': True},\n",
    "            'anthropic': {'transformers': ['claude-3-5-sonnet-20240620'], 'key': os.getenv('ANTHROPIC_API_KEY'),'active': False},\n",
    "            'google': {'transformers': ['gemini-1.5-flash'],'key': os.getenv('GOOGLE_API_KEY'),'active': True}            \n",
    "        }\n",
    "\n",
    "        self.results: str =''\n",
    "       \n",
    "\n",
    "    def instantiate_model(self, model_name, metadata):\n",
    "        key=metadata['key']\n",
    "\n",
    "        if model_name == 'openai' and metadata['active'] == True:\n",
    "            for model in metadata['transformers']: \n",
    "                openai.key = key\n",
    "                completion = openai.chat.completions.create(\n",
    "                        model=model,\n",
    "                        temperature=metadata['temperature'],\n",
    "                        messages = [\n",
    "                            {'role':'system','content': self.system_prompt},\n",
    "                            {'role':'user','content': self.user_prompt}                        \n",
    "                        ]\n",
    "                    )\n",
    "\n",
    "                self.results += completion.choices[0].message.content + '\\n'\n",
    "\n",
    "        elif model_name == 'google' and metadata['active'] == True:\n",
    "            for model in metadata['transformers']: \n",
    "                genai.configure(api_key=key)\n",
    "                gemini = genai.GenerativeModel(\n",
    "                        model_name=model\n",
    "                        #system_instruction=[self.system_prompt]\n",
    "                )\n",
    "\n",
    "                response = gemini.generate_content(self.user_prompt)\n",
    "                self.results += response.text + '\\n'\n",
    "\n",
    "        elif model_name == 'anthropic' and metadata['active'] == True:\n",
    "            for model in metadata['transformers']:\n",
    "                anthro = anthropic.Anthropic(               \n",
    "                    api_key=key\n",
    "                )\n",
    "                message = anthro.messages.create(\n",
    "                        model=model,\n",
    "                        \n",
    "                        max_tokens=200,\n",
    "                        system=self.system_prompt,\n",
    "                        messages = [                           \n",
    "                            {'role':'user','content': self.user_prompt}                        \n",
    "                        ]\n",
    "                )\n",
    "\n",
    "                self.results += message.content[0].text + '\\n'\n",
    "\n",
    "        return self\n",
    "\n",
    "        \n",
    "    def create_jokes(self):                \n",
    "        for frontier in self.frontier_list:\n",
    "            metadata = self.llm_models.get(frontier)\n",
    "            \n",
    "            self.instantiate_model(frontier,metadata)\n",
    "        \n",
    "        \n",
    "        return self\n",
    "\n",
    "    def view(self):\n",
    "        display(Markdown(self.results))\n",
    "        return self\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Why did the dad bring a ladder to the barbeque?\n",
       "\n",
       "Because he heard the steaks were \"medium rare\"! ðŸ˜‚ðŸ¥©\n",
       "\n",
       "Created by davinci-003\n",
       "Why did the dad bring a ladder to the bar?\n",
       "\n",
       "Because he heard the drinks were on the house!\n",
       "\n",
       "(created by gpt-3.5-turbo)\n",
       "Why did the dad bring a ladder to the bar?\n",
       "\n",
       "Because he heard the drinks were on the house and wanted to make sure he could reach them, but ended up being the first dad ever to get \"high\" without even touching a drink!\n",
       "\n",
       "Created by gpt-3.5-turbo\n",
       "Why did the dad take his son to the bank? \n",
       "\n",
       "To get his \"loan\" shark! \n",
       "\n",
       "---\n",
       "\n",
       "Why did the dad get fired from the bank?\n",
       "\n",
       "He kept saying, \"I'm just here for the deposit!\" \n",
       "\n",
       "---\n",
       "\n",
       "Why don't dads ever win at hide-and-seek?\n",
       "\n",
       "Because they always get found out! \n",
       "\n",
       "---\n",
       "\n",
       "What did the dad say when his son asked him for advice on how to become a comedian?\n",
       "\n",
       "\"Son, just be yourself! That's funny enough!\" \n",
       "\n",
       "---\n",
       "\n",
       "What did the dad say to the kid who was complaining about his new pet goldfish? \n",
       "\n",
       "\"Don't worry, son. He's just a little fishtastic!\" \n",
       "\n",
       "---\n",
       "\n",
       "Why are dads bad at playing hide and seek? \n",
       "\n",
       "They're always found out! \n",
       "\n",
       "---\n",
       "\n",
       "What did the dad say when his son asked him for advice on how to impress a girl? \n",
       "\n",
       "\"Just be yourself, son! But maybe wear a tie.\" \n",
       "\n",
       "---\n",
       "\n",
       "Why did the dad get a job at the zoo? \n",
       "\n",
       "Because he was a real \"lion\"hearted father! \n",
       "\n",
       "---\n",
       "\n",
       "What do you call a dad who's really good at telling jokes?\n",
       "\n",
       "A dad-joke master! \n",
       "\n",
       "---\n",
       "\n",
       "Why did the dad get a job as a baker? \n",
       "\n",
       "He's a real \"dough\"-nut! \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.TheJoker at 0x1b2e2aba7d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    TheJoker('Father')\n",
    "        .create_jokes()\n",
    "        .view()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative-llm-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
