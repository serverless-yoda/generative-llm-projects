{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-ai-textanalytics==5.3.0\n",
      "  Downloading azure_ai_textanalytics-5.3.0-py3-none-any.whl.metadata (82 kB)\n",
      "Collecting azure-core<2.0.0,>=1.24.0 (from azure-ai-textanalytics==5.3.0)\n",
      "  Using cached azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting azure-common~=1.1 (from azure-ai-textanalytics==5.3.0)\n",
      "  Using cached azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting isodate<1.0.0,>=0.6.1 (from azure-ai-textanalytics==5.3.0)\n",
      "  Using cached isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in c:\\users\\ma2\\.conda\\envs\\generative-llm-projects\\lib\\site-packages (from azure-ai-textanalytics==5.3.0) (4.12.2)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\ma2\\.conda\\envs\\generative-llm-projects\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.3.0) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\ma2\\.conda\\envs\\generative-llm-projects\\lib\\site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.3.0) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ma2\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.3.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ma2\\.conda\\envs\\generative-llm-projects\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.3.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ma2\\.conda\\envs\\generative-llm-projects\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.3.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ma2\\.conda\\envs\\generative-llm-projects\\lib\\site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics==5.3.0) (2024.8.30)\n",
      "Downloading azure_ai_textanalytics-5.3.0-py3-none-any.whl (298 kB)\n",
      "Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Using cached azure_core-1.32.0-py3-none-any.whl (198 kB)\n",
      "Using cached isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: azure-common, isodate, azure-core, azure-ai-textanalytics\n",
      "Successfully installed azure-ai-textanalytics-5.3.0 azure-common-1.1.28 azure-core-1.32.0 isodate-0.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-ai-textanalytics==5.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, uuid, json,os\n",
    "from dotenv import load_dotenv\n",
    "from enum import Enum\n",
    "from openai import AzureOpenAI  \n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient #azure-ai-textanalytics==5.3.0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIServiceType(Enum):\n",
    "    OPENAI_LANGUAGEAPI = 'Language'\n",
    "    OPENAI_DALLE = 'Dall-e'\n",
    "    OPENAI_WHISPER = 'Whisper'\n",
    "    SPEECH_TO_TEXT='SpeechToText'\n",
    "    TEXT_TO_SPEECH='TextToSpeech'\n",
    "    CUSTOM_VOICE='CustomVoice'\n",
    "    CONTENT_SAFETY='ContentSafety'\n",
    "    COMPUTER_VISION='ComputerVision'\n",
    "    LANGUAGE='Language'\n",
    "    TEXT_TRANSLATION='TextTranslation'\n",
    "    DOCUMENT_TRANSLATION='DocumentTranslation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AzureAIExamples:\n",
    "    def __init__(self, aiservice_type):\n",
    "        _ = load_dotenv()\n",
    "        self.key = os.environ['AZUREAI_TOKEN']\n",
    "        self.location = os.environ['AZURE_LOCATION']\n",
    "        self.aiservice_type = aiservice_type\n",
    "        self.based_endpoint = os.environ['BASED_ENDPOINT']\n",
    "        self.cognitive_service_url = os.environ['AZUREAI_COGNITIVESERVICES_URL']\n",
    "\n",
    "        self.params = {\n",
    "            'api-version': '3.0'\n",
    "        }\n",
    "\n",
    "        self.headers = {\n",
    "            'Ocp-Apim-Subscription-Key': self.key,\n",
    "            # location required if you're using a multi-service or regional (not global) resource.\n",
    "            'Ocp-Apim-Subscription-Region': self.location,\n",
    "            'Content-type': 'application/json',\n",
    "            'X-ClientTraceId': str(uuid.uuid4())\n",
    "        }\n",
    "\n",
    "    \n",
    "    def get_language(self,text):\n",
    "        credential = AzureKeyCredential(self.key)\n",
    "        client = TextAnalyticsClient(endpoint=self.cognitive_service_url,credential=credential)\n",
    "\n",
    "        detectedlanguage = client.detect_language(documents=[text])[0]\n",
    "        print(detectedlanguage)\n",
    "        print(detectedlanguage.primary_language.name)\n",
    "\n",
    "    def get_text_translation(self, input_text):\n",
    "        #cognitive_services_endpoint = os.environ['AZUREAI_COGNITIVESERVICES_URL']\n",
    "        translator_endpoint = os.environ['AZUREAI_TRANSLATOR_URL']\n",
    "        \n",
    "        path = '/translate'\n",
    "        constructed_url = translator_endpoint + path\n",
    "\n",
    "        params['from'] = 'en'\n",
    "        params['to']= ['fr', 'zu','zh-Hans']\n",
    "        \n",
    "        # You can pass more than one object in body.\n",
    "        body = [{\n",
    "            'text': input_text\n",
    "        }]\n",
    "\n",
    "        request = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
    "        response = request.json()\n",
    "\n",
    "\n",
    "        print(json.dumps(response, sort_keys=True, ensure_ascii=False, indent=4, separators=(',', ': ')))\n",
    "\n",
    "    def chat_completions(self, input_text):\n",
    "        endpoint = f\"https://{self.based_endpoint}.openai.azure.com/\"  \n",
    "        deployment =  \"gpt-35-turbo-16k\"  \n",
    "        subscription_key = self.key  \n",
    "    \n",
    "        # Initialize Azure OpenAI client with key-based authentication\n",
    "        client = AzureOpenAI(  \n",
    "            azure_endpoint=endpoint,  \n",
    "            api_key=subscription_key,  \n",
    "            api_version=\"2024-05-01-preview\",  \n",
    "        )  \n",
    "      \n",
    "        system_prompt = \"\"\"\n",
    "            You are an AI Historian that helps people find information anything about historical places,people or anything that \n",
    "            have importance in world history.\n",
    "\n",
    "            Your answer should be accurate and if you dont know anything just say 'No I dont have any idea right now'\n",
    "\n",
    "            Make your answer funny.\n",
    "        \"\"\"\n",
    "        # Prepare the chat prompt  \n",
    "        chat_prompt = [\n",
    "            {\n",
    "                \"role\": \"system\", \"content\": system_prompt,\n",
    "                \"role\": \"user\", \"content\": input_text\n",
    "            }\n",
    "        ]  \n",
    "    \n",
    "        # Include speech result if speech is enabled  \n",
    "        speech_result = chat_prompt  \n",
    "        \n",
    "        # Generate the completion  \n",
    "        completion = client.chat.completions.create(  \n",
    "            model=deployment,  \n",
    "            messages=speech_result,  \n",
    "            #past_messages=10,  \n",
    "            max_tokens=800,  \n",
    "            temperature=0.7,  \n",
    "            top_p=0.95,  \n",
    "            frequency_penalty=0,  \n",
    "            presence_penalty=0,  \n",
    "            stop=None,  \n",
    "            stream=False  \n",
    "        )  \n",
    "        \n",
    "        formatted_response = {\n",
    "            \"response\": {\n",
    "                \"content\": completion.choices[0].message.content,\n",
    "                \"role\": completion.choices[0].message.role,\n",
    "                \"finish_reason\": completion.choices[0].finish_reason\n",
    "            },\n",
    "            \"metadata\": {\n",
    "                \"model\": completion.model,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"prompt_tokens\": completion.usage.prompt_tokens,\n",
    "                \"completion_tokens\": completion.usage.completion_tokens,\n",
    "                \"total_tokens\": completion.usage.total_tokens\n",
    "            },\n",
    "            \"request_info\": {\n",
    "                \"deployment\": deployment,\n",
    "                \"max_tokens\": 800,\n",
    "                \"temperature\": 0.7,\n",
    "                \"top_p\": 0.95\n",
    "            }\n",
    "        }\n",
    "\n",
    "        #print(formatted_response)\n",
    "        print(json.dumps(formatted_response, sort_keys=True, ensure_ascii=False, indent=4, separators=(',', ': ')))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = AzureAIExamples(aiservice_type=AIServiceType.TEXT_TRANSLATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai.get_text_translation('What are the good tourist destinations in France')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ai.chat_completions('Where can you find the holy grail?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0', 'primary_language': DetectedLanguage(name=French, iso6391_name=fr, confidence_score=0.89), 'warnings': [], 'statistics': None, 'is_error': False, 'kind': 'LanguageDetection'}\n",
      "French\n"
     ]
    }
   ],
   "source": [
    "ai.get_language(\"Boun Jour\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative-llm-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
