{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, uuid, json,os\n",
    "from dotenv import load_dotenv\n",
    "from enum import Enum\n",
    "from openai import AzureOpenAI  \n",
    "from datetime import datetime\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIServiceType(Enum):\n",
    "    OPENAI_LANGUAGEAPI = 'Language'\n",
    "    OPENAI_DALLE = 'Dall-e'\n",
    "    OPENAI_WHISPER = 'Whisper'\n",
    "    SPEECH_TO_TEXT='SpeechToText'\n",
    "    TEXT_TO_SPEECH='TextToSpeech'\n",
    "    CUSTOM_VOICE='CustomVoice'\n",
    "    CONTENT_SAFETY='ContentSafety'\n",
    "    COMPUTER_VISION='ComputerVision'\n",
    "    LANGUAGE='Language'\n",
    "    TEXT_TRANSLATION='TextTranslation'\n",
    "    DOCUMENT_TRANSLATION='DocumentTranslation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AzureAIExamples:\n",
    "    def __init__(self, aiservice_type):\n",
    "        _ = load_dotenv()\n",
    "        self.key = os.environ['AZUREAI_TOKEN']\n",
    "        self.location = os.environ['AZURE_LOCATION']\n",
    "        self.aiservice_type = aiservice_type\n",
    "        self.based_endpoint = os.environ['BASED_ENDPOINT']\n",
    "\n",
    "        self.params = {\n",
    "            'api-version': '3.0'\n",
    "        }\n",
    "\n",
    "        self.headers = {\n",
    "            'Ocp-Apim-Subscription-Key': self.key,\n",
    "            # location required if you're using a multi-service or regional (not global) resource.\n",
    "            'Ocp-Apim-Subscription-Region': location,\n",
    "            'Content-type': 'application/json',\n",
    "            'X-ClientTraceId': str(uuid.uuid4())\n",
    "        }\n",
    "\n",
    "    \n",
    "    \n",
    "    def get_text_translation(self, input_text):\n",
    "        #cognitive_services_endpoint = os.environ['AZUREAI_COGNITIVESERVICES_URL']\n",
    "        translator_endpoint = os.environ['AZUREAI_TRANSLATOR_URL']\n",
    "        \n",
    "        path = '/translate'\n",
    "        constructed_url = translator_endpoint + path\n",
    "\n",
    "        params['from'] = 'en'\n",
    "        params['to']= ['fr', 'zu','zh-Hans']\n",
    "        \n",
    "        # You can pass more than one object in body.\n",
    "        body = [{\n",
    "            'text': input_text\n",
    "        }]\n",
    "\n",
    "        request = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
    "        response = request.json()\n",
    "\n",
    "\n",
    "        print(json.dumps(response, sort_keys=True, ensure_ascii=False, indent=4, separators=(',', ': ')))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def chat_completions(self, input_text):\n",
    "        endpoint = f\"https://{self.based_endpoint}.openai.azure.com/\"  \n",
    "        deployment =  \"gpt-35-turbo-16k\"  \n",
    "        subscription_key = self.key  \n",
    "    \n",
    "        # Initialize Azure OpenAI client with key-based authentication\n",
    "        client = AzureOpenAI(  \n",
    "            azure_endpoint=endpoint,  \n",
    "            api_key=subscription_key,  \n",
    "            api_version=\"2024-05-01-preview\",  \n",
    "        )  \n",
    "      \n",
    "        system_prompt = \"\"\"\n",
    "            You are an AI Historian that helps people find information anything about historical places,people or anything that \n",
    "            have importance in world history.\n",
    "\n",
    "            Your answer should be accurate and if you dont know anything just say 'No I dont have any idea right now'\n",
    "\n",
    "            Make your answer funny.\n",
    "        \"\"\"\n",
    "        # Prepare the chat prompt  \n",
    "        chat_prompt = [\n",
    "            {\n",
    "                \"role\": \"system\", \"content\": system_prompt,\n",
    "                \"role\": \"user\", \"content\": input_text\n",
    "            }\n",
    "        ]  \n",
    "    \n",
    "        # Include speech result if speech is enabled  \n",
    "        speech_result = chat_prompt  \n",
    "        \n",
    "        # Generate the completion  \n",
    "        completion = client.chat.completions.create(  \n",
    "            model=deployment,  \n",
    "            messages=speech_result,  \n",
    "            #past_messages=10,  \n",
    "            max_tokens=800,  \n",
    "            temperature=0.7,  \n",
    "            top_p=0.95,  \n",
    "            frequency_penalty=0,  \n",
    "            presence_penalty=0,  \n",
    "            stop=None,  \n",
    "            stream=False  \n",
    "        )  \n",
    "        \n",
    "        formatted_response = {\n",
    "            \"response\": {\n",
    "                \"content\": completion.choices[0].message.content,\n",
    "                \"role\": completion.choices[0].message.role,\n",
    "                \"finish_reason\": completion.choices[0].finish_reason\n",
    "            },\n",
    "            \"metadata\": {\n",
    "                \"model\": completion.model,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"prompt_tokens\": completion.usage.prompt_tokens,\n",
    "                \"completion_tokens\": completion.usage.completion_tokens,\n",
    "                \"total_tokens\": completion.usage.total_tokens\n",
    "            },\n",
    "            \"request_info\": {\n",
    "                \"deployment\": deployment,\n",
    "                \"max_tokens\": 800,\n",
    "                \"temperature\": 0.7,\n",
    "                \"top_p\": 0.95\n",
    "            }\n",
    "        }\n",
    "\n",
    "        #print(formatted_response)\n",
    "        print(json.dumps(formatted_response, sort_keys=True, ensure_ascii=False, indent=4, separators=(',', ': ')))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai = AzureAIExamples(aiservice_type=AIServiceType.TEXT_TRANSLATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai.get_text_translation('What are the good tourist destinations in France')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ai.chat_completions('Where can you find the holy grail?')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative-llm-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
