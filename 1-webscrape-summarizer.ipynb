{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebscraperSummarizer:\n",
    "    url: str\n",
    "    title:str\n",
    "    content:str\n",
    "    system_prompt: str\n",
    "    user_prompt: str\n",
    "    context: list()\n",
    "    summarized_content: str\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content,'html.parser')\n",
    "\n",
    "        self.title = soup.title.string if soup.title else 'no title found'\n",
    "        \n",
    "        #remove tags\n",
    "        for tags in soup.body(['script','style','img','input']):\n",
    "            tags.decompose()\n",
    "        \n",
    "        self.content = soup.body.get_text(separator='\\n', strip=True)\n",
    "        load_dotenv()\n",
    "        #os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "        openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "        \n",
    "        self.system_prompt = \"\"\"You are a reliable assistant that analyze website content. \n",
    "                                You provide a good summary and navigation links and images. \n",
    "                                You translate technical words to a very understable way.\n",
    "                                You always respond in markdown.\"\"\"\n",
    "\n",
    "        self.user_prompt = f\"You are reading  this website {self.title}\"\n",
    "        self.user_prompt += \"The contents of this website is as follows;\" + self.content \n",
    "        self.user_prompt += \"Provide a short summary of this website. Summarize news or announcement.\\n\\n\"\n",
    "        self.user_prompt += \"The final summary should be in structured as markdown.\\n\\n\"\n",
    "\n",
    "\n",
    "    def messages(self):\n",
    "        self.context = [\n",
    "             {'role':'system', 'content': self.system_prompt},\n",
    "             {'role':'user',   'content': self.user_prompt},\n",
    "         ]\n",
    "       \n",
    "        \n",
    "        return self\n",
    "\n",
    "    def summarizer(self):\n",
    "        \n",
    "        response=openai.chat.completions.create(\n",
    "            model='gpt-4o-mini',\n",
    "            messages=self.context)\n",
    "        \n",
    "        self.summarized_content=response.choices[0].message.content\n",
    "        return self\n",
    "\n",
    "    def view(self):\n",
    "        display(Markdown(self.summarized_content))\n",
    "        return self\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://edition.cnn.com/'\n",
    "(\n",
    "                WebscraperSummarizer(url)\n",
    "                        .messages()\n",
    "                        .summarizer()\n",
    "                        .view()\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative-llm-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
